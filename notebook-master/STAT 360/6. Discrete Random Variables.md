### **Introduction to Random Variable**

*Discrete Random Variables* takes values from a countable set.

*Continuous Random Variable* takes values from an interval of real number

___

### **Poisson Distribution**

Let $X =$ number of text messages a student receives in one hour
$X$ takes values $0,1,2,3$
Modeled with a *Poisson Distribution*

$$P(X = k) = \frac{e^{-\lambda}\lambda^k}{k!}, \; k = 0,1,2 ...$$
where $\lambda =$ average texts per hour.

Note: doesn't have an upper bound!

___

### **Binomial Distribution**

Let $X =$ number of successful free throws out of $10$ attempts
$X$ takes values $0,1,2,...,10$
Modeled with a *Binomial Distribution*
$$P(X=k) = \binom{10}{k} p^k(1-p)^{10 - k}$$
where $p =$ player's probability of making one shot

Random variables help teams evaluate performance and strategy.

___

### **More**

Random variables let us define
- Expectation (long-run average)
- Variance (variability)
- Distributions (full probability model)

Essential for
- Hypothesis Testing
- Confidence Intervals
- Prediction & Decision Making

___


### **Discrete Random Variable**

- For a given sample space $S$ of some experiment, a *random variable*, is any rule associates a number with each outcome of $S$.
- In mathematical language, a random variable

___

### **Probability Mass Function**

The *probability distribution* or *probability mass function* of a discrete random variable is defined for every number $x$ by $p(x) = \Pr(X=x)$

___

### **Cumulative Distribution Function**

The *cumulative distribution function* $F(x)$ of a discrete random variable $X$ with probability mass function $p(x)$ is defined for every member $x$ by
$$F(x) = \Pr(X \le x) = \sum\limits_{y:y \le x}p(y)$$

For any member $x$, $F(x)$ is the probability that the observed value of $X$ will be at most $x$.

___

### **Expected Value of X**

Let $X$ be a discrete random variable with probability mass function $p(x)$. The *expected value* or *mean* of $X$, denoted by 
$$E(X) = \mu_x = \sum x\cdot p(x)$$

___

### **Expectation of a Function**

If the random variable $X$ has a probability mass function $p(x)$, then the expectation of any function $h(X)$ denoted $E[h(X)]$ or $\mu_{h(X)}$ is computed by:
$$E[h(X)] = \sum h(x) \cdot p(x)$$

The expectation for a linear function follows directly:
$$E[aX + b] = a\cdot E[x] + b$$

___

### **Variance of X**

Let $X$ have probability mass function $p(x)$ and expectation $\mu$.
Then the *variance* of $X$, denoted $V(X)$ or $\sigma^2$, is
$$V(X) = \sigma^2 = \sum(x-\mu)^2 \cdot p(x) = E[(X-\mu)^2]$$

The *standard deviation* of $X$ is
$$\sigma = \sqrt{\sigma^2}$$

$\sigma^2 = E[x^2] - E[x]^2$

___

### **Binomial Probability Distribution**

- An experiment consists of a sequence of $n$ smaller experiments called trials, where $n$ is fixed in advance of the experiment
- Each trial can result in one of the same two possible outcomes ("Success" pr "Failure")
- The trials are independent, so that the outcome of any particular trial does not influence the outcome of any other trial
- The probability of success is constant from trial to trial; we denote this probability $p$

$$\text{Bin}(x; n,p) = \Pr(X=x) = \binom{n}{x}p^x(1-p)^{n-x}$$

$$E(X) = \mu = np$$
$$Var(X) = \sigma^2 = np(1-p)$$
$$\sigma = \sqrt{np(1-p)}$$

___

### **Poisson Probability Distribution**

A random variable $X$ is said to have a *Poisson distribution* with parameter $\lambda$ ($\lambda > 0$) if the pmf of $X$ is
$$p(x, \lambda) = \Pr(X = x) = \frac{e^{\lambda}\lambda^x}{x!}\;\text{for }x=0,1,2,...$$

The value of $\lambda$ is frequently a rate per unit time or per unit area

$E(X) = E(V)$

### **Poisson & Binomial Distributions**

- For binomial experiments where $n$ is large and $p$ is small, the distribution is approximately Poisson with $\lambda = np$.
- As a general rule of thumb, the approximation can be safely applied if $n > 50$ and $np < 5$


### **Poisson Rate $\lambda$ (intuitive)**

If the number of events that can occur in a time interval are independent with a mean rate $\lambda$ and there are $t$ disjoint time intervals, then $X =$ the number of events occurring in the $t$ time intervals follows a poisson distribution $\lambda t$