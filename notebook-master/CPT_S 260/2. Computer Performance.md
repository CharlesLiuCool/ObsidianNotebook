### **Block Diagram of a Computer**

- *Registers:* Set of memory very close to the processor
	- Hold frequently used data
- *Main Memory*
	- Dynamic memory that holds data and programs currently running
	- RAM in common terminology
- *Secondary Memory*
	- Permanent storage
	- Hard disks, CD, DVD, etc.

### **Measuring Computer Performance**

*Response Time* - Execution time
- How long it takes to do a task

*Throughput*
- Total work done per unit time

How are response time and throughput affected by:
- Replacing the processor with a faster version
- Adding more processors

*Elapsed Time*
- Total response time, including all aspects
	- Processing, I/O, OS overhead, idle time
- Determines system performance

*CPU Time*
- Time spent processing a given job
	- Discounts I/O time, other jobs' shares
- Comprises over user CPU time and system CPU time

**Relative Performance** $= 1/\text{Execution Time}$

X is *n* time faster than y

Example:
$10$s on $A$, 15s on $B$
Execution time $= 15/10 = 1.5$
So $A$ is $1.5$ times faster than $B$

*CPU Clock*
(conductor of the orchestra)

- Operation of digital hardware governed by a constant rate clock

*Instructions Run over Multiple Clocks*

- Each program is compiled into a *set of instructions*
- *Note:* Number of instructions in a program is an important metric!
- Instructions tell the hardware operation to perform
- *Instruction Set Architecture (ISA)* is a group of commands for a processor
	- Like different software languages but for different CPU architectures

We are going to follow *MIPS* instruction set architecture.

*CPU Time* - Total time required for running an instruction

$= \text{\# CPU Clock Cycles} \times \text{Clock Cycle Time} = \dfrac{\text{\# CPU Clock Cycles}}{\text{Clock Rate}}$

*Performance improved by:*
- Reducing number of clock cycles
- Increasing clock rate
- Hardware designer must often trade of clock rate and cycle count

$\text{Clock Cycles} = \text{Instruction Count} \times \text{Cycles per Instruction}$

$\text{CPU Time} = \text{Instruction Count} \times \text{CPI} \times \text{Clock Cycle Time}$ 

$= \dfrac{\text{Instruction Count} \times \text{CPI}}{\text{Clock Rate}}$

CPI = Clocks per instruction

|                 | Instruction Count | CPI | Clock Rate |
| --------------- | ----------------- | --- | ---------- |
| Program         | X                 |     |            |
| Compiler        | X                 | X   |            |
| Instruction Set | X                 | X   |            |
| Organization    |                   | X   | X          |
| Technology      |                   |     | X          |

*Benchmarking CPUs based on CPU time*

- CPU Time: time it takes for a CPU to execute an instruction
- Computer A: Cycle Time = 250ps, CPI = 2.0
- Computer B : Cycle Time: 500ps, CPI = 1.2

Same Program, same ISA -> same instructions/program

*CPI in more detail*

$$\text{Clock Cycles} = \sum\limits_{i=1}^n (\text{CPI}_i \times \text{Instruction Count}_i)$$

### **Amdahl's Law**

>[!lightbulb] Amdahl's Law
>Improving an aspect of a computer and expecting a proportional improvement in overall performance

For instance multiplication

Bring a/b | Multiply | Store back in memory
Memory Fetch | Multiplication Operation | Memory Store

![[2. Computer Performance 2025-08-20 14.48.46.excalidraw]]

If we want to optimize this, and say we can't optimize the memory, then we can only optimize the multiply operation by an *improvement factor*.

We are optimizing $T_\text{affected}$. Other parts are $T_\text{unaffected}$

After improvement, $T_\text{affected}$ is improved by $\dfrac{T_\text{affected}}{\text{Improvement Factor}}$

We want to find
$$T_\text{improved} = \dfrac{T_\text{affected}}{\text{Improvement Factor}} + T_\text{unaffected}$$

